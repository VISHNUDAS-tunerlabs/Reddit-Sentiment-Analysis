# ğŸ›‰ Reddit Data Cleanup & Sentiment Analysis

Welcome to the **Reddit Data Cleanup & Sentiment Analysis** repository!  
This tool helps you analyze the sentiment of Reddit submissions provided in JSON format and outputs a single CSV file summarizing the results â€” all with a beginner-friendly setup.

---

## ğŸ“ Repository Structure

```
Reddit-Sentiment-Analysis/
â”œâ”€â”€ input/                      # Folder containing input .json files (sample files included)
â”‚   â”œâ”€â”€ sample1.json
â”‚   â””â”€â”€ sample2.json
â”œâ”€â”€ sentimentAnalysis.py       # Python script to perform sentiment analysis
â”œâ”€â”€ output.csv                 # Output CSV (auto-generated after running the script)
â””â”€â”€ README.md                  # This file
```

---

## ğŸ”§ Features

- Accepts `.json` files of Reddit submissions placed inside the `input/` folder.
- Performs sentiment analysis using **NLTK's SentimentIntensityAnalyzer**.
- Outputs a single `output.csv` summarizing sentiment scores per day.

---

## ğŸš€ Getting Started

No prior experience? No worries â€” follow these steps to set up everything from scratch!

### 1. Clone the Repository

```bash
git clone https://github.com/VISHNUDAS-tunerlabs/Reddit-Sentiment-Analysis
cd reddit-data-cleanup
```

### 2. Set Up a Virtual Environment

It's recommended to use a virtual environment to manage dependencies:

```bash
# Create a virtual environment
python3 -m venv venv

# Activate the virtual environment
# On macOS/Linux:
source venv/bin/activate

# On Windows:
venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

> If there's no `requirements.txt`, just run:

```bash
pip install nltk pandas
```

And don't forget to download NLTK resources:

```python
# Run this in a Python shell
import nltk
nltk.download('vader_lexicon')
```

---

## â–¶ï¸ Running the Script

Once everything is set up, simply run:

```bash
python sentimentAnalysis.py
```

This will:

- Read all `.json` files in the `input/` folder.
- Perform sentiment analysis on each submission.
- Generate a single `output.csv` file in the root directory.

---

## ğŸ“‚ Sample Data

We've included a couple of sample `.json` files inside the `input/` folder so you can test the script right away.

---

## ğŸ“Œ Notes

- Make sure your `.json` files contain a top-level field named `submissions`, where each item has a `created_utc` timestamp and `body` or `text` for sentiment analysis.
- The script assumes the timestamp is in UNIX format and converts it to daily aggregation.

---

## ğŸ¤ Contributing

Feel free to fork the repo and contribute via pull requests. Suggestions and improvements are always welcome!

---

## ğŸ“¬ Contact

Have questions or need help? Open an issue or reach out!
